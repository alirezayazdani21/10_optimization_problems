{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QXhpHmVRb_J8VmO_5luyGkV1kCLzoi8r",
      "authorship_tag": "ABX9TyMKRUgBL9FEMcVTdVRXLHeQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezayazdani21/10_optimization_problems/blob/master/Outlier_detection_methods_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outlier detection\n",
        "\n",
        "outlier detection for time series data involves identifying data points that deviate significantly from the expected pattern or behavior of the series. There are several methods you can use to detect outliers in time series data using Python. Here are a few examples:\n"
      ],
      "metadata": {
        "id": "fSwxqdjCbQ2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Z-Score Method:** The z-score method measures the deviation of a data point from the mean in terms of standard deviations. Generally, a z-score above a certain threshold (e.g., 3) is considered an outlier."
      ],
      "metadata": {
        "id": "faoqi7cTMliM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.random.randn(1000)  # Replace with your own time series data\n",
        "\n",
        "# Calculate z-scores\n",
        "z_scores = np.abs(stats.zscore(data))\n",
        "\n",
        "# Set threshold for outliers, e.g. 3 standard deviations\n",
        "threshold = 3\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(z_scores > threshold)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)\n",
        "\n",
        "plt.figure(figsize=(8,5));\n",
        "plt.plot(data);\n",
        "plt.scatter(outlier_indices,data[outlier_indices], marker='*', color='red');"
      ],
      "metadata": {
        "id": "6t_q4zg-X57p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Median Absolute Deviation (MAD) Method:** The MAD method calculates the deviation of each data point from the median of the series in terms of median absolute deviation. Typically, a data point is considered an outlier if its MAD exceeds a certain threshold.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "weZM2J_hW7P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import uniform_filter\n",
        "\n",
        "# Set window size\n",
        "window_size = 30\n",
        "\n",
        "# Calculate mean and standard deviation within the window\n",
        "rolling_mean = uniform_filter(data, size=window_size)\n",
        "rolling_std = np.std(data)\n",
        "\n",
        "# Calculate z-scores for each data point\n",
        "z_scores = (data - rolling_mean) / rolling_std\n",
        "\n",
        "# Set threshold for outliers\n",
        "threshold = 3\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(np.abs(z_scores) > threshold)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)"
      ],
      "metadata": {
        "id": "7TIxABypZMzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moving Z-Score Method:** The moving z-score method calculates the z-score for each data point within a moving window. Outliers are detected based on the z-scores exceeding a certain threshold.\n",
        "\n"
      ],
      "metadata": {
        "id": "ralDHuS5f1Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import uniform_filter\n",
        "\n",
        "# Set window size\n",
        "window_size = 30\n",
        "\n",
        "# Calculate mean and standard deviation within the window\n",
        "rolling_mean = uniform_filter(data, size=window_size)\n",
        "rolling_std = np.std(data)\n",
        "\n",
        "# Calculate z-scores for each data point\n",
        "z_scores = (data - rolling_mean) / rolling_std\n",
        "\n",
        "# Set threshold for outliers\n",
        "threshold = 3\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(np.abs(z_scores) > threshold)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)\n",
        "\n"
      ],
      "metadata": {
        "id": "Uc_9aUIbf3xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantile Method:** The quantile method involves calculating the lower and upper quantiles of the data distribution and considering data points outside of this range as outliers.\n"
      ],
      "metadata": {
        "id": "86sJVwMJ3iBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set quantile thresholds\n",
        "lower_quantile = 0.01\n",
        "upper_quantile = 0.99\n",
        "\n",
        "# Calculate quantiles\n",
        "lower_threshold = np.quantile(data, lower_quantile)\n",
        "upper_threshold = np.quantile(data, upper_quantile)\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where((data < lower_threshold) | (data > upper_threshold))[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)\n",
        "\n",
        "plt.figure(figsize=(8,5));\n",
        "plt.plot(data);\n",
        "plt.scatter(outlier_indices,data[outlier_indices], marker='*', color='red');"
      ],
      "metadata": {
        "id": "32K7RFcm3oYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Robust Z-Score Method:** The robust z-score method uses the median and median absolute deviation (MAD) instead of the mean and standard deviation to measure the deviation of data points from the expected behavior.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U0P6ObB0XBO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate median and median absolute deviation (MAD)\n",
        "median_val = np.median(data)\n",
        "mad = np.median(np.abs(data - median_val))\n",
        "\n",
        "# Calculate robust z-scores\n",
        "robust_z_scores = 0.6745 * (data - median_val) / mad\n",
        "\n",
        "# Set threshold for outliers\n",
        "threshold = 3\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(np.abs(robust_z_scores) > threshold)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)\n"
      ],
      "metadata": {
        "id": "04UHOWu44qAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moving Median Absolute Deviation (MAD) Method:** Similar to the moving z-score method, this approach calculates the median and median absolute deviation within a moving window. Outliers are identified based on the deviation from the window's median.\n"
      ],
      "metadata": {
        "id": "PIoisxPO49bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import median_filter\n",
        "\n",
        "# Set window size\n",
        "window_size = 30\n",
        "\n",
        "# Calculate median within the window\n",
        "rolling_median = median_filter(data, size=window_size)\n",
        "\n",
        "# Calculate median absolute deviation (MAD) within the window\n",
        "rolling_mad = np.median(np.abs(data - rolling_median))\n",
        "\n",
        "# Set threshold for outliers\n",
        "threshold = 3\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(np.abs(data - rolling_median) / rolling_mad > threshold)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)"
      ],
      "metadata": {
        "id": "gd4olu0X5A2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autoregressive Integrated Moving Average (ARIMA) Residuals:** If you have fitted an ARIMA model to your time series data, you can examine the residuals to identify outliers. Unusually large residuals can indicate the presence of outliers.\n",
        "\n"
      ],
      "metadata": {
        "id": "VDVs3Bwh5X1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Fit ARIMA model to the time series data\n",
        "model = sm.tsa.ARIMA(data, order=(2, 2, 1))  # Replace p, d, q with appropriate values\n",
        "arima_model = model.fit()\n",
        "\n",
        "# Get residuals\n",
        "residuals = arima_model.resid\n",
        "\n",
        "# Set threshold for outliers\n",
        "threshold = 3\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(np.abs(residuals) > threshold)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)\n",
        "plt.plot(residuals)\n",
        "plt.scatter(outlier_indices,data[outlier_indices], marker='*', color='red');"
      ],
      "metadata": {
        "id": "6wZAbrWf5aGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-Class Support Vector Machines (SVM):**\n",
        "One-Class SVM is a machine learning algorithm that can be used for outlier detection. It learns the normal pattern of the data and identifies points that deviate significantly from it.\n"
      ],
      "metadata": {
        "id": "fOPgSZ7e6I7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "# Fit One-Class SVM model\n",
        "model = OneClassSVM(nu=0.05)  # Adjust nu parameter based on your data\n",
        "model.fit(data.reshape(-1, 1))  # Reshape data if needed\n",
        "\n",
        "# Predict outliers\n",
        "outliers = model.predict(data.reshape(-1, 1)) == -1\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(outliers)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)\n"
      ],
      "metadata": {
        "id": "iT6Ry9IC6Kbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Isolation Forest:**\n",
        "Isolation Forest is an ensemble algorithm that separates outliers by randomly partitioning the data. It measures the number of partitions needed to isolate an instance, and outliers tend to require fewer partitions.\n"
      ],
      "metadata": {
        "id": "m7TwLYYP6jXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Fit Isolation Forest model\n",
        "model = IsolationForest(contamination=0.05)  # Adjust contamination parameter based on your data\n",
        "model.fit(data.reshape(-1, 1))  # Reshape data if needed\n",
        "\n",
        "# Predict outliers\n",
        "outliers = model.predict(data.reshape(-1, 1)) == -1\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(outliers)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)\n"
      ],
      "metadata": {
        "id": "nJcRIOnu6lVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Local Outlier Factor (LOF):** is an unsupervised outlier detection algorithm that measures the local density deviation of a data point with respect to its neighbors. Here's an example of how you can use the LocalOutlierFactor for outlier detection in time series data:\n"
      ],
      "metadata": {
        "id": "hcDJZUEKXkZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Generate sample time series data\n",
        "data = np.random.randn(1000, 1)  # Replace with your own time series data\n",
        "\n",
        "# Fit the Local Outlier Factor model\n",
        "lof = LocalOutlierFactor(contamination=0.05)  # Adjust the contamination parameter based on your data\n",
        "outlier_scores = lof.fit_predict(data)\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(outlier_scores == -1)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ti4zmwBnMaYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elliptic Envelope:** This is a robust method that fits an elliptical envelope to the data and identifies outliers as points lying outside the envelope (this is based on Mahalanobis distance, a measure of the distance between a point and a distribution.). Here's an example of how you can use the Elliptic Envelope for outlier detection in time series data:"
      ],
      "metadata": {
        "id": "Tpkhl9F2Z1ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "\n",
        "# Generate sample time series data\n",
        "data = np.random.randn(1000, 1)  # Replace with your own time series data\n",
        "\n",
        "# Fit the Elliptic Envelope model\n",
        "envelope = EllipticEnvelope(contamination=0.05)  # Adjust the contamination parameter based on your data\n",
        "envelope.fit(data)\n",
        "\n",
        "# Predict outliers\n",
        "outliers = envelope.predict(data) == -1\n",
        "\n",
        "# Find outlier indices\n",
        "outlier_indices = np.where(outliers)[0]\n",
        "\n",
        "# Print outlier indices\n",
        "print(\"Outlier indices:\", outlier_indices)\n"
      ],
      "metadata": {
        "id": "FGTPPjNqaZ9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the Elliptic Envelope model is fitted to the time series data. The contamination parameter is used to control the expected proportion of outliers in the data. Outliers are predicted using the predict() method, and the indices of the outliers are extracted."
      ],
      "metadata": {
        "id": "MSCKHhQQaiC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change Point Detection:**\n",
        "Change point detection focuses on identifying points in a time series where the underlying pattern or behavior changes significantly. These points can indicate the presence of outliers or shifts in the data distribution.\n",
        "\n",
        "One popular approach for change point detection is using the `ruptures` library in Python. It provides various algorithms to detect change points in time series data. Here's an example using the Pelt algorithm:\n"
      ],
      "metadata": {
        "id": "i21NgOoq8Enf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ruptures\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ruptures as rpt\n",
        "\n",
        "# Generate sample time series data\n",
        "\n",
        "# Perform change point detection\n",
        "algo = rpt.Pelt(model=\"rbf\")\n",
        "algo.fit(data)\n",
        "result = algo.predict(pen=12)\n",
        "\n",
        "# Plot the time series data with change points\n",
        "plt.plot(data)\n",
        "for point in result:\n",
        "    plt.axvline(x=point, color='r', linestyle='--')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Time Series with Change Points')\n",
        "plt.show();\n",
        "\n",
        "# Print change point indices\n",
        "print(\"Change point indices:\", result)\n"
      ],
      "metadata": {
        "id": "5OQwkGEo8Kjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this example, the `ruptures` library is used to detect change points in the time series data. The Pelt algorithm is applied with a penalty value (`pen`) to control the sensitivity of change point detection. The resulting change point indices are plotted as vertical lines on the time series plot.\n",
        "\n",
        "You can explore other algorithms provided by the `ruptures` library, such as `BinarySeg` or `Dynp`, to find the most suitable approach for your specific data."
      ],
      "metadata": {
        "id": "oEDiz4qZ84pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "#!pip install pypandoc\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!cp \"./drive/MyDrive/Colab Notebooks/Outlier_detection.ipynb\" ./\n",
        "!jupyter nbconvert --to PDF \"Outlier_detection.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ov83BUshoaP",
        "outputId": "74d5d80b-92de-4de5-a859-173746c349f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook Outlier_detection.ipynb to PDF\n",
            "[NbConvertApp] Support files will be in Outlier_detection_files/\n",
            "[NbConvertApp] Making directory ./Outlier_detection_files\n",
            "[NbConvertApp] Making directory ./Outlier_detection_files\n",
            "[NbConvertApp] Making directory ./Outlier_detection_files\n",
            "[NbConvertApp] Making directory ./Outlier_detection_files\n",
            "[NbConvertApp] Writing 57245 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 236167 bytes to Outlier_detection.pdf\n"
          ]
        }
      ]
    }
  ]
}